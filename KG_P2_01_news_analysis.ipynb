{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b735da82",
   "metadata": {},
   "source": [
    "# Neo4j와 LangChain을 활용한 뉴스 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27cc8b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Neo4J Desktop 환경 설정\n",
    "\n",
    "- **Neo4j Desktop 소개**:\n",
    "    - Neo4j 작업을 위한 클라이언트 애플리케이션\n",
    "    - 로컬 환경에서 Neo4j를 학습하고 실험하는 데 필요한 모든 것을 포함함\n",
    "    - 사용자의 컴퓨터 리소스가 허용하는 한 **여러 로컬 데이터베이스**를 생성할 수 있음\n",
    "    - **Enterprise Edition 라이센스**: 단, 개발자 개인에 대해서는 1개 계정을 테스트 목적으로 지원\n",
    "\n",
    "- **다운로드 및 설치**: https://neo4j.com/deployment-center/?desktop-gdb\n",
    "    - Neo4J 5.24.0 선택\n",
    "    - 새 프로젝트 생성 및 DBMS 추가\n",
    "\n",
    "- **APOC 플러그인 설정**: \n",
    "    - APOC 플러그인을 설치하려는 데이터베이스가 있는 프로젝트(Graph DBMS)를 선택\n",
    "    - Graph DBMS 메뉴 클릭하고, APOC 플러그인(Plugin) 설치\n",
    "\n",
    "- **설정 파일 수정**: 데이터베이스를 중지한 상태에서 데이터베이스 카드의 오른쪽에 있는 `...` (메뉴) 버튼을 클릭\n",
    "\n",
    "    - 메뉴에서 **Settings** 선택하고 다음 내용을 추가 (`neo4j.conf` 파일)\n",
    "        ```\n",
    "        dbms.security.procedures.unrestricted=apoc.meta.*,apoc.*\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc7d00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42b4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "# LangChain 도구 활용 - DB 연결 객체 초기화 \n",
    "graph = Neo4jGraph( \n",
    "    url=os.getenv(\"NEO4J_URI\"), \n",
    "    username=os.getenv(\"NEO4J_USERNAME\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    database=os.getenv(\"NEO4J_DATABASE\"),\n",
    "    enhanced_schema=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a4a57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n': {'name': 'Hello Neo4j Desktop News DB'}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 쿼리 실행 \n",
    "cypher_query = \"\"\"\n",
    "CREATE (n:Test {name: \"Hello Neo4j Desktop News DB\"}) \n",
    "RETURN n\n",
    "\"\"\"\n",
    "\n",
    "graph.query(cypher_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22382171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터베이스가 초기화되었습니다.\n"
     ]
    }
   ],
   "source": [
    "def reset_database(graph):\n",
    "    \"\"\"\n",
    "    APOC 없이 데이터베이스 초기화하기\n",
    "    \"\"\"\n",
    "    # 모든 노드와 관계 삭제\n",
    "    graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "    \n",
    "    # 모든 제약조건 삭제\n",
    "    constraints = graph.query(\"SHOW CONSTRAINTS\")\n",
    "    for constraint in constraints:\n",
    "        constraint_name = constraint.get(\"name\")\n",
    "        if constraint_name:\n",
    "            graph.query(f\"DROP CONSTRAINT {constraint_name}\")\n",
    "    \n",
    "    # 모든 인덱스 삭제\n",
    "    indexes = graph.query(\"SHOW INDEXES\")\n",
    "    for index in indexes:\n",
    "        index_name = index.get(\"name\")\n",
    "        index_type = index.get(\"type\")\n",
    "        if index_name and index_type != \"CONSTRAINT\":\n",
    "            graph.query(f\"DROP INDEX {index_name}\")\n",
    "    \n",
    "    print(\"데이터베이스가 초기화되었습니다.\")\n",
    "\n",
    "# 데이터베이스 초기화\n",
    "reset_database(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e27da72",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. **Knowledge Graph 구축**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81769e02",
   "metadata": {},
   "source": [
    "### 2.1 뉴스 데이터 전처리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5f243",
   "metadata": {},
   "source": [
    "#### 1) **데이터셋 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd4f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 데이터 목록:\n",
      "news_article_1.md\n",
      "news_article_2.md\n",
      "news_article_3.md\n",
      "news_article_4.md\n",
      "news_article_5.md\n",
      "\n",
      "뉴스 데이터:\n",
      "\n",
      "뉴스 기사 1:\n",
      "# 구글, 안드로이드 14에 생성형 AI 기능 대거 탑재\n",
      "\n",
      "**디지털타임스 | 박승리 기자 | 2024-03-20**\n",
      "\n",
      "구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 2:\n",
      "# 애플, iOS 18 공개하며 AI 플랫폼 경쟁 본격화\n",
      "\n",
      "**디지털타임스 | 최기상 기자 | 2024-03-19**\n",
      "\n",
      "애플이 차세대 모바일 운영체제 iOS 18을 공개하며 AI ...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 3:\n",
      "# 메타, 차세대 오픈소스 AI 모델 'Llama 3' 공개\n",
      "\n",
      "**디지털타임스 | 정주리 기자 | 2024-04-05**\n",
      "\n",
      "메타가 차세대 오픈소스 AI 모델 'Llama 3'를 공...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 4:\n",
      "# 삼성전자, 'AI 메모리' 신기술 개발 성공\n",
      "\n",
      "**전자일보 | 이승지 기자 | 2024-04-03**\n",
      "\n",
      "삼성전자가 AI 연산에 최적화된 '컴퓨팅 인 메모리'(CIM) 기술을 적...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 5:\n",
      "# 엔비디아, 차세대 AI 전용 GPU 'H200' 출시 임박\n",
      "\n",
      "**전자일보 | 김송이 기자 | 2024-04-02**\n",
      "\n",
      "엔비디아가 차세대 AI 전용 GPU 'H200'의 출시가 ...\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 데이터 로드\n",
    "def load_news_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        news_article = file.read()\n",
    "    return news_article\n",
    "\n",
    "# 뉴스 데이터 목록 확인 (glob)\n",
    "import glob\n",
    "news_files = sorted(glob.glob(os.path.join('news_data', '*.md')))\n",
    "\n",
    "# 뉴스 데이터 목록 출력\n",
    "print(\"뉴스 데이터 목록:\")\n",
    "for news_file in news_files:\n",
    "    print(os.path.basename(news_file))\n",
    "\n",
    "# 뉴스 데이터 로드 및 정리\n",
    "news_articles = []\n",
    "for news_file in news_files:\n",
    "    news_article = load_news_data(news_file)\n",
    "    news_articles.append(news_article)\n",
    "\n",
    "# 뉴스 데이터 출력\n",
    "print(\"\\n뉴스 데이터:\")\n",
    "for i, news_article in enumerate(news_articles):\n",
    "    print(f\"\\n뉴스 기사 {i + 1}:\\n{news_article[:100]}...\")  # 첫 100자만 출력\n",
    "    print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c718188",
   "metadata": {},
   "source": [
    "#### 2) **뉴스 메타데이터 추출**\n",
    "\n",
    "- 랭체인 구조화 출력 활용 (LLM 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7855e7e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     84\u001b[39m extracted_metadata = []\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m news_articles:\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# 각 기사에서 메타데이터 추출\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     metadata = \u001b[43mextract_article_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# 추출된 메타데이터 저장\u001b[39;00m\n\u001b[32m     89\u001b[39m     extracted_metadata.append(metadata)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mextract_article_metadata\u001b[39m\u001b[34m(article_text)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# 메타데이터 추출 시도\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# LLM을 통해 메타데이터 추출\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     metadata = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marticle_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43marticle_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# 데이터 누락 시, 기본값 설정 - 데이터 일관성 유지\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metadata.title:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3254\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3252\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3253\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3254\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3255\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5720\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5713\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5714\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5715\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5718\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5719\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5721\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5723\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     **kwargs: Any,\n\u001b[32m   1023\u001b[39m ) -> LLMResult:\n\u001b[32m   1024\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1181\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1178\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1179\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1180\u001b[39m     raw_response = (\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1184\u001b[39m     )\n\u001b[32m   1185\u001b[39m     response = raw_response.parse()\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:184\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    179\u001b[39m         response_format=response_format,\n\u001b[32m    180\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    181\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1294\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1285\u001b[39m     warnings.warn(\n\u001b[32m   1286\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1288\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1289\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1290\u001b[39m     )\n\u001b[32m   1291\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1292\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=to_httpx_files(files), **options\n\u001b[32m   1293\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1002\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1000\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1008\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import date\n",
    "\n",
    "# 뉴스 기사 메타데이터 모델 정의\n",
    "class NewsArticleMetadata(BaseModel):\n",
    "    \"\"\"뉴스 기사의 구조화된 메타데이터.\"\"\"\n",
    "    title: str = Field(description=\"뉴스 기사의 제목\")\n",
    "    source: str = Field(description=\"뉴스 출처/발행처\")\n",
    "    author: str = Field(description=\"기사 작성자의 이름 (직위 등 표시 불필요)\")\n",
    "    date: str = Field(description=\"발행일(YYYY-MM-DD 형식)\")\n",
    "    content: str = Field(description=\"기사의 전체 텍스트 내용\")\n",
    "\n",
    "def extract_article_metadata(article_text: str) -> NewsArticleMetadata:\n",
    "    \"\"\"\n",
    "    Langchain을 사용하여 뉴스 기사에서 구조화된 메타데이터를 추출합니다.\n",
    "    \n",
    "    Args:\n",
    "        article_text (str): 뉴스 기사의 전체 텍스트\n",
    "    \n",
    "    Returns:\n",
    "        NewsArticleMetadata: 기사에서 추출한 구조화된 메타데이터\n",
    "    \"\"\"\n",
    "\n",
    "    # 프롬프트 템플릿 정의 - LLM에게 메타데이터 추출 지시사항 제공\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert news article metadata extractor. \n",
    "        Extract precise and accurate information from the given news article.\n",
    "        \n",
    "        Extraction Guidelines:\n",
    "        - Identify the most accurate title\n",
    "        - Determine the primary source/publication\n",
    "        - Extract the author's name (only name, no position)\n",
    "        - Identify the publication date\n",
    "        - List key organizations mentioned\n",
    "        - Highlight key technologies discussed\n",
    "        \n",
    "        Be as specific and factual as possible.\"\"\"),\n",
    "        (\"human\", \"\"\"Extract metadata from the following article:\\n\\n{article_text}\"\"\")\n",
    "    ])\n",
    "\n",
    "    # LLM 및 체인 설정\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)    \n",
    "\n",
    "    # 구조화된 출력을 위해 Pydantic 모델과 연결\n",
    "    llm_with_structured_output = llm.with_structured_output(NewsArticleMetadata)\n",
    "    \n",
    "    # 프롬프트와 LLM을 연결하는 체인 구성\n",
    "    chain = prompt | llm_with_structured_output\n",
    "    \n",
    "    # 메타데이터 추출 시도\n",
    "    try:\n",
    "        # LLM을 통해 메타데이터 추출\n",
    "        metadata = chain.invoke({\n",
    "            \"article_text\": article_text,\n",
    "        })\n",
    "        \n",
    "        # 데이터 누락 시, 기본값 설정 - 데이터 일관성 유지\n",
    "        if not metadata.title:\n",
    "            metadata.title = \"\"\n",
    "        if not metadata.source:\n",
    "            metadata.source = \"미상\"\n",
    "        if not metadata.author:\n",
    "            metadata.author = \"미상\"\n",
    "        if not metadata.date:\n",
    "            metadata.date = \"미상\"\n",
    "        if not metadata.content:\n",
    "            metadata.content = article_text\n",
    "        \n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        # 에러 발생 시 로그 출력 및 기본 메타데이터 반환\n",
    "        print(f\"메타데이터 추출 중 오류 발생: {e}\")\n",
    "        return NewsArticleMetadata(\n",
    "            title=\"\",\n",
    "            source=\"미상\",\n",
    "            author=\"미상\",\n",
    "            date=\"미상\",\n",
    "            content=\"\"\n",
    "        )\n",
    "\n",
    "# 모든 뉴스 기사에서 메타데이터 추출 및 결과 출력\n",
    "extracted_metadata = []\n",
    "for article in news_articles:\n",
    "    # 각 기사에서 메타데이터 추출\n",
    "    metadata = extract_article_metadata(article)\n",
    "    # 추출된 메타데이터 저장\n",
    "    extracted_metadata.append(metadata)\n",
    "    # 추출 결과 출력 - 디버깅 및 확인용\n",
    "    print(f\"Extracted metadata for article: {metadata.title}\")\n",
    "    print(f\"Source: {metadata.source}\")\n",
    "    print(f\"Author: {metadata.author}\")\n",
    "    print(f\"Date: {metadata.date}\")\n",
    "    print(f\"Content: {metadata.content[:100]}...\")  # 첫 100자만 출력하여 가독성 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51b240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '구글, 안드로이드 14에 생성형 AI 기능 대거 탑재',\n",
       " 'source': '디지털타임스',\n",
       " 'author': '박승리',\n",
       " 'date': '2024-03-20',\n",
       " 'content': '구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고 발표했다. 이번 발표는 구글의 인공지능 기술력을 한층 강화하는 전략의 일환으로 보인다. 특히 카메라 기능에서 AI를 활용한 사진 보정 기능이 크게 개선되었으며, 사용자가 촬영한 사진을 인공지능이 자동으로 분석하여 최적의 색감과 구도로 보정해주는 기능이 추가되었다. 또한 실시간 번역 기능도 대폭 강화되어 외국어 텍스트를 카메라로 비추기만 해도 즉시 번역 결과를 확인할 수 있고, 통화 중에도 실시간 음성 번역 기능이 추가되었다. 구글 어시스턴트는 생성형 AI 기술을 적용해 더 자연스러운 대화가 가능해졌으며, 복잡한 질문에 정확한 답변을 제공하고 개인화된 서비스를 제공한다. 구글 안드로이드 부문 책임자는 이번 AI 기능이 사용자 경험을 혁신적으로 개선할 것이라고 밝혔다. 업계 전문가들은 이번 AI 기능 강화가 모바일 OS 시장에서 경쟁력을 높이는 중요한 전환점이 될 것으로 전망하고 있다.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_metadata[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9dfba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터를 JSONL 형식으로 저장\n",
    "import json\n",
    "with open('news_data/news_metadata.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for metadata in extracted_metadata:\n",
    "        json.dump(metadata.model_dump(), f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 메타데이터:\n",
      "\n",
      "뉴스 기사 1:\n",
      "Title: 구글, 안드로이드 14에 생성형 AI 기능 대거 탑재\n",
      "Source: 디지털타임스\n",
      "Author: 박승리\n",
      "Date: 2024-03-20\n",
      "Content: 구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고 발표했다. 이번 발표는 구글의 인공지능 기술력을 한층 강화하는 전략의 일환으로 보인다. 특히 카메라 기능에서 AI를 활...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 2:\n",
      "Title: 애플, iOS 18 공개하며 AI 플랫폼 경쟁 본격화\n",
      "Source: 디지털타임스\n",
      "Author: 최기상\n",
      "Date: 2024-03-19\n",
      "Content: 애플이 차세대 모바일 운영체제 iOS 18을 공개하며 AI 플랫폼 경쟁을 본격화하고 있다. 최근 샌프란시스코에서 열린 WWDC 2024에서 공개된 iOS 18은 애플의 인공지능 전...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 3:\n",
      "Title: 메타, 차세대 오픈소스 AI 모델 'Llama 3' 공개\n",
      "Source: 디지털타임스\n",
      "Author: 정주리\n",
      "Date: 2024-04-05\n",
      "Content: 메타가 차세대 오픈소스 AI 모델 'Llama 3'를 공개했다. 이번 모델은 이전 버전보다 2배 큰 파라미터 규모와 10배 많은 학습 데이터를 기반으로 개발되었다고 회사 측은 밝혔...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 4:\n",
      "Title: 삼성전자, 'AI 메모리' 신기술 개발 성공\n",
      "Source: 전자일보\n",
      "Author: 이승지\n",
      "Date: 2024-04-03\n",
      "Content: 삼성전자가 AI 연산에 최적화된 '컴퓨팅 인 메모리'(CIM) 기술을 적용한 신개념 메모리 반도체 개발에 성공했다고 발표했다. 이번 기술은 기존 메모리와 CPU 간의 데이터 이동 ...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "뉴스 기사 5:\n",
      "Title: 엔비디아, 차세대 AI 전용 GPU 'H200' 출시 임박\n",
      "Source: 전자일보\n",
      "Author: 김송이\n",
      "Date: 2024-04-02\n",
      "Content: 엔비디아가 차세대 AI 전용 GPU 'H200'의 출시가 임박했다고 발표했다. 이번 신제품은 기존 H100 대비 2배 이상의 성능을 제공할 것으로 알려졌다. H200은 대형 언어 ...\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# JSONL 파일 확인\n",
    "import json\n",
    "with open('news_data/news_metadata.jsonl', 'r', encoding='utf-8') as f:\n",
    "    news_metadata = [json.loads(line) for line in f]\n",
    "    print(\"뉴스 메타데이터:\")\n",
    "    for i, metadata in enumerate(news_metadata):\n",
    "        print(f\"\\n뉴스 기사 {i + 1}:\")\n",
    "        print(f\"Title: {metadata['title']}\")\n",
    "        print(f\"Source: {metadata['source']}\")\n",
    "        print(f\"Author: {metadata['author']}\")\n",
    "        print(f\"Date: {metadata['date']}\")\n",
    "        print(f\"Content: {metadata['content'][:100]}...\")  # 첫 100자만 출력\n",
    "        print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719ec2e",
   "metadata": {},
   "source": [
    "#### 3) **뉴스 데이터 구조화**\n",
    "\n",
    "- 추출한 메타데이터 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681310ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구조화된 뉴스 기사 데이터:\n",
      "ID: article_0\n",
      "Title: 구글, 안드로이드 14에 생성형 AI 기능 대거 탑재\n",
      "Source: 디지털타임스\n",
      "Author: 박승리\n",
      "Date: 2024-03-20\n",
      "Content: 구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고 발표했다. 이번 발표는 구글의 인공지능 기술력을 한층 강화하는 전략의 일환으로 보인다. 특히 카메라 기능에서 AI를 활...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ID: article_1\n",
      "Title: 애플, iOS 18 공개하며 AI 플랫폼 경쟁 본격화\n",
      "Source: 디지털타임스\n",
      "Author: 최기상\n",
      "Date: 2024-03-19\n",
      "Content: 애플이 차세대 모바일 운영체제 iOS 18을 공개하며 AI 플랫폼 경쟁을 본격화하고 있다. 최근 샌프란시스코에서 열린 WWDC 2024에서 공개된 iOS 18은 애플의 인공지능 전...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ID: article_2\n",
      "Title: 메타, 차세대 오픈소스 AI 모델 'Llama 3' 공개\n",
      "Source: 디지털타임스\n",
      "Author: 정주리\n",
      "Date: 2024-04-05\n",
      "Content: 메타가 차세대 오픈소스 AI 모델 'Llama 3'를 공개했다. 이번 모델은 이전 버전보다 2배 큰 파라미터 규모와 10배 많은 학습 데이터를 기반으로 개발되었다고 회사 측은 밝혔...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ID: article_3\n",
      "Title: 삼성전자, 'AI 메모리' 신기술 개발 성공\n",
      "Source: 전자일보\n",
      "Author: 이승지\n",
      "Date: 2024-04-03\n",
      "Content: 삼성전자가 AI 연산에 최적화된 '컴퓨팅 인 메모리'(CIM) 기술을 적용한 신개념 메모리 반도체 개발에 성공했다고 발표했다. 이번 기술은 기존 메모리와 CPU 간의 데이터 이동 ...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ID: article_4\n",
      "Title: 엔비디아, 차세대 AI 전용 GPU 'H200' 출시 임박\n",
      "Source: 전자일보\n",
      "Author: 김송이\n",
      "Date: 2024-04-02\n",
      "Content: 엔비디아가 차세대 AI 전용 GPU 'H200'의 출시가 임박했다고 발표했다. 이번 신제품은 기존 H100 대비 2배 이상의 성능을 제공할 것으로 알려졌다. H200은 대형 언어 ...\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 데이터 구조화 - JSONL 파일에서 로드한 메타데이터를 분석 가능한 형태로 변환\n",
    "\n",
    "extracted_articles = []  # 구조화된 뉴스 기사를 저장할 빈 리스트 초기화\n",
    "\n",
    "# 각 뉴스 메타데이터를 순회하면서 구조화된 형태로 변환\n",
    "for i, article in enumerate(news_metadata):\n",
    "    \n",
    "    # 개별 기사 데이터 구조화 - 일관된 형식으로 데이터 정리\n",
    "    # - id: 고유 식별자 부여 (article_0, article_1 등의 형식)\n",
    "    # - 제목, 출처, 작성자, 날짜, 내용 등 핵심 정보 포함\n",
    "    article = {\n",
    "        \"id\": f\"article_{i}\",  # 고유 식별자 생성 (인덱스 기반)\n",
    "        \"title\": article[\"title\"],  # 기사 제목\n",
    "        \"source\": article[\"source\"],  # 기사 출처 (언론사)\n",
    "        \"author\": article[\"author\"],  # 기사 작성자\n",
    "        \"date\": article[\"date\"],  # 기사 발행일\n",
    "        \"content\": article[\"content\"]  # 기사 전체 내용\n",
    "    }\n",
    "\n",
    "    # 구조화된 기사 데이터를 리스트에 추가 - 이후 지식 그래프 구축에 활용\n",
    "    extracted_articles.append(article)\n",
    "\n",
    "# 구조화된 기사 데이터 확인 - 처리 결과 검증 및 디버깅\n",
    "print(\"구조화된 뉴스 기사 데이터:\")\n",
    "for article in extracted_articles:\n",
    "    print(f\"ID: {article['id']}\")  # 고유 식별자 출력\n",
    "    print(f\"Title: {article['title']}\")  # 기사 제목 출력\n",
    "    print(f\"Source: {article['source']}\")  # 출처 출력\n",
    "    print(f\"Author: {article['author']}\")  # 작성자 출력\n",
    "    print(f\"Date: {article['date']}\")  # 날짜 출력\n",
    "    print(f\"Content: {article['content'][:100]}...\")  # 내용 일부만 출력하여 가독성 확보\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794f552",
   "metadata": {},
   "source": [
    "### 2.2 KG 온톨로지 구현\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e4644",
   "metadata": {},
   "source": [
    "#### 1) **스키마 정의**\n",
    "\n",
    "- **노드 유형**:\n",
    "\n",
    "    1. `NewsArticle`: 뉴스 기사\n",
    "    2. `Company`: 회사\n",
    "    3. `Product`: 제품\n",
    "    4. `Technology`: 기술\n",
    "\n",
    "\n",
    "- **관계 유형**:\n",
    "\n",
    "    - `(NewsArticle)-[:MENTIONS]->(Entity)`\n",
    "    - `(Company)-[:RELEASED]->(Product)`\n",
    "    - `(Company)-[:DEVELOPED]->(Technology)`\n",
    "    - `(Product)-[:USES]->(Technology)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dba54e",
   "metadata": {},
   "source": [
    "#### 2) **제약조건 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j 데이터베이스에 Cypher 쿼리를 사용하여 제약조건 설정\n",
    "# 제약조건은 노드의 특정 속성이 고유(UNIQUE)하도록 보장하여 데이터 중복을 방지함\n",
    "constraints = [\n",
    "    # NewsArticle 노드의 id 속성이 고유하도록 제약조건 설정\n",
    "    # 이를 통해 동일한 id를 가진 뉴스 기사가 중복 저장되는 것을 방지\n",
    "    \"CREATE CONSTRAINT IF NOT EXISTS FOR (n:NewsArticle) REQUIRE n.id IS UNIQUE\",\n",
    "    \n",
    "    # Company 노드의 name 속성이 고유하도록 제약조건 설정\n",
    "    # 동일한 이름의 회사가 여러 번 생성되는 것을 방지\n",
    "    \"CREATE CONSTRAINT IF NOT EXISTS FOR (c:Company) REQUIRE c.name IS UNIQUE\",\n",
    "    \n",
    "    # Product 노드의 name 속성이 고유하도록 제약조건 설정\n",
    "    # 동일한 이름의 제품이 중복 생성되는 것을 방지\n",
    "    \"CREATE CONSTRAINT IF NOT EXISTS FOR (p:Product) REQUIRE p.name IS UNIQUE\",\n",
    "    \n",
    "    # Technology 노드의 name 속성이 고유하도록 제약조건 설정\n",
    "    # 동일한 이름의 기술이 중복 생성되는 것을 방지\n",
    "    \"CREATE CONSTRAINT IF NOT EXISTS FOR (t:Technology) REQUIRE t.name IS UNIQUE\",\n",
    "    \n",
    "    # Person 노드의 name 속성이 고유하도록 제약조건 설정\n",
    "    # 동일한 이름의 인물이 중복 생성되는 것을 방지\n",
    "    \"CREATE CONSTRAINT IF NOT EXISTS FOR (p:Person) REQUIRE p.name IS UNIQUE\",\n",
    "]\n",
    "\n",
    "# 정의된 모든 제약조건을 순회하며 Neo4j 데이터베이스에 적용\n",
    "# graph.query() 메서드를 사용하여 각 Cypher 쿼리를 실행\n",
    "for constraint in constraints:\n",
    "    graph.query(constraint)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629fea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 9,\n",
       "  'name': 'constraint_43bf92ef',\n",
       "  'type': 'UNIQUENESS',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Person'],\n",
       "  'properties': ['name'],\n",
       "  'ownedIndex': 'constraint_43bf92ef',\n",
       "  'propertyType': None},\n",
       " {'id': 7,\n",
       "  'name': 'constraint_676af2eb',\n",
       "  'type': 'UNIQUENESS',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Technology'],\n",
       "  'properties': ['name'],\n",
       "  'ownedIndex': 'constraint_676af2eb',\n",
       "  'propertyType': None},\n",
       " {'id': 0,\n",
       "  'name': 'constraint_8b429a9c',\n",
       "  'type': 'UNIQUENESS',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['NewsArticle'],\n",
       "  'properties': ['id'],\n",
       "  'ownedIndex': 'constraint_8b429a9c',\n",
       "  'propertyType': None},\n",
       " {'id': 3,\n",
       "  'name': 'constraint_bc3ece84',\n",
       "  'type': 'UNIQUENESS',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Company'],\n",
       "  'properties': ['name'],\n",
       "  'ownedIndex': 'constraint_bc3ece84',\n",
       "  'propertyType': None},\n",
       " {'id': 5,\n",
       "  'name': 'constraint_ef0216e9',\n",
       "  'type': 'UNIQUENESS',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Product'],\n",
       "  'properties': ['name'],\n",
       "  'ownedIndex': 'constraint_ef0216e9',\n",
       "  'propertyType': None}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"SHOW CONSTRAINTS\")  # 현재 설정된 제약조건 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4740ec",
   "metadata": {},
   "source": [
    "#### 3) **뉴스 기사에서 엔티티와 관계를 추출**\n",
    "\n",
    "- 랭체인 `LLMGraphTransformer` 초기화\n",
    "- langchain_experimental 설치\n",
    "\n",
    "- https://python.langchain.com/docs/how_to/graph_constructing/#llm-graph-transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f652fc",
   "metadata": {},
   "source": [
    "`(1) LLMGraphTransformer 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94719e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any  \n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_core.documents import Document  \n",
    "\n",
    "# LLM(대규모 언어 모델) 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "# 그래프 데이터베이스에서 사용할 엔티티(노드) 유형 정의\n",
    "# 뉴스 기사에서 추출할 엔티티 타입을 제한하여 정확도 향상\n",
    "allowed_nodes = [\"Company\", \"Product\", \"Technology\"]\n",
    "\n",
    "# 엔티티 간의 관계 유형 정의\n",
    "# (시작 노드 유형, 관계 유형, 끝 노드 유형) 형태로 허용되는 관계 명시\n",
    "allowed_relationships = [\n",
    "    (\"Company\", \"RELEASED\", \"Product\"),     # 회사가 제품을 출시함\n",
    "    (\"Company\", \"DEVELOPED\", \"Technology\"), # 회사가 기술을 개발함\n",
    "    (\"Product\", \"USES\", \"Technology\")       # 제품이 기술을 사용함\n",
    "]\n",
    "\n",
    "# LLM Graph Transformer 초기화 및 설정\n",
    "# 텍스트에서 그래프 구조(노드와 관계)를 추출하는 변환기 설정\n",
    "transformer = LLMGraphTransformer(\n",
    "    llm=llm,                               # 사용할 언어 모델\n",
    "    allowed_nodes=allowed_nodes,           # 허용되는 노드 유형\n",
    "    allowed_relationships=allowed_relationships,  # 허용되는 관계 유형\n",
    "    node_properties=[\"industry\", \"version\", \"releaseDate\", \"category\"]  # 노드에 추가할 수 있는 속성들\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a407488",
   "metadata": {},
   "source": [
    "`(2) 뉴스 기사에서 그래프 데이터 추출`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0fe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환된 문서 수: 5\n",
      "====================================================================================================\n",
      "구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고 발표했다. 이번 발표는 구글의 인공지능 기술력을 한층 강화하는 전략의 일환으로 보인다. 특히 카메라 기능에서 AI를 활\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'id': 'article_0', 'title': '구글, 안드로이드 14에 생성형 AI 기능 대거 탑재', 'source': '디지털타임스', 'author': '박승리', 'date': '2024-03-20'}\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 기사 데이터를 LangChain의 Document 객체로 변환하는 함수\n",
    "# - LangChain의 Document 객체는 텍스트 콘텐츠와 메타데이터를 함께 저장할 수 있는 구조\n",
    "# - 이를 통해 LLM이 문서 처리 시 메타데이터 정보도 함께 활용 가능\n",
    "def convert_to_documents(articles: List[Dict[str, Any]]) -> List[Document]:\n",
    "    documents = []\n",
    "    for article in articles:\n",
    "        # 각 기사마다 Document 객체 생성\n",
    "        # - page_content: 기사 본문 내용 저장\n",
    "        # - metadata: 기사의 부가 정보(ID, 제목, 출처, 작성자, 날짜) 저장\n",
    "        doc = Document(\n",
    "            page_content=article[\"content\"],\n",
    "            metadata={\n",
    "                \"id\": article[\"id\"],\n",
    "                \"title\": article[\"title\"],\n",
    "                \"source\": article[\"source\"],\n",
    "                \"author\": article[\"author\"],\n",
    "                \"date\": article[\"date\"]\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents\n",
    "\n",
    "# 앞서 추출한 뉴스 기사(extracted_articles)를 LangChain Document 객체 리스트로 변환\n",
    "# - 이 변환을 통해 LLMGraphTransformer가 처리할 수 있는 형태로 데이터 준비\n",
    "documents = convert_to_documents(extracted_articles)\n",
    "print(f\"변환된 문서 수: {len(documents)}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# 변환된 첫 번째 문서의 내용 확인 (디버깅 및 검증 목적)\n",
    "print(documents[0].page_content[:100])  # 첫 100자만 출력하여 내용 미리보기\n",
    "print(\"-\" * 100)\n",
    "print(documents[0].metadata)  # 문서의 메타데이터 전체 출력 (ID, 제목, 출처 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0dd8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래프 문서 수: 5\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 기사에서 그래프 데이터 추출\n",
    "# - LLMGraphTransformer를 사용하여 일반 문서를 그래프 구조로 변환\n",
    "# - 각 문서(뉴스 기사)에서 노드(회사, 기술, 제품 등)와 관계(개발, 출시, 사용 등)를 추출\n",
    "# - LLM이 텍스트를 분석하여 허용된 노드 유형과 관계 유형에 맞게 구조화된 데이터 생성\n",
    "# - 추출된 그래프 데이터는 Neo4j에 저장하기 위한 중간 형태로 사용됨\n",
    "\n",
    "graph_documents = transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "# 변환된 그래프 문서의 수를 출력하여 처리 결과 확인\n",
    "print(f\"그래프 문서 수: {len(graph_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0defdcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node(id='구글', type='Company', properties={'industry': 'technology'}),\n",
       " Node(id='안드로이드 14', type='Product', properties={'version': '14', 'category': 'mobile operating system'}),\n",
       " Node(id='생성형 Ai', type='Technology', properties={'category': 'artificial intelligence'}),\n",
       " Node(id='사진 보정 기능', type='Technology', properties={'category': 'image processing'}),\n",
       " Node(id='실시간 번역 기능', type='Technology', properties={'category': 'translation'}),\n",
       " Node(id='실시간 음성 번역 기능', type='Technology', properties={'category': 'speech translation'}),\n",
       " Node(id='구글 어시스턴트', type='Product', properties={'category': 'virtual assistant'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0].nodes  # 첫 번째 그래프 문서의 노드 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9333f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Relationship(source=Node(id='구글', type='Company', properties={}), target=Node(id='안드로이드 14', type='Product', properties={}), type='RELEASED', properties={}),\n",
       " Relationship(source=Node(id='구글', type='Company', properties={}), target=Node(id='생성형 Ai', type='Technology', properties={}), type='DEVELOPED', properties={}),\n",
       " Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='생성형 Ai', type='Technology', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='사진 보정 기능', type='Technology', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='실시간 번역 기능', type='Technology', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='실시간 음성 번역 기능', type='Technology', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='구글 어시스턴트', type='Product', properties={}), target=Node(id='생성형 Ai', type='Technology', properties={}), type='USES', properties={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[0].relationships  # 첫 번째 그래프 문서의 관계 정보 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af4f76",
   "metadata": {},
   "source": [
    "`(3) 추출된 그래프 데이터를 Neo4j에 저장`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9bbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추출된 노드: [Node(id='구글', type='Company', properties={'industry': 'technology'}), Node(id='안드로이드 14', type='Product', properties={'version': '14', 'category': 'mobile operating system'}), Node(id='생성형 Ai', type='Technology', properties={'category': 'artificial intelligence'}), Node(id='사진 보정 기능', type='Technology', properties={'category': 'image processing'}), Node(id='실시간 번역 기능', type='Technology', properties={'category': 'translation'}), Node(id='실시간 음성 번역 기능', type='Technology', properties={'category': 'speech translation'}), Node(id='구글 어시스턴트', type='Product', properties={'category': 'virtual assistant'})]\n",
      "추출된 관계: [Relationship(source=Node(id='구글', type='Company', properties={}), target=Node(id='안드로이드 14', type='Product', properties={}), type='RELEASED', properties={}), Relationship(source=Node(id='구글', type='Company', properties={}), target=Node(id='생성형 Ai', type='Technology', properties={}), type='DEVELOPED', properties={}), Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='생성형 Ai', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='사진 보정 기능', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='실시간 번역 기능', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='안드로이드 14', type='Product', properties={}), target=Node(id='실시간 음성 번역 기능', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='구글 어시스턴트', type='Product', properties={}), target=Node(id='생성형 Ai', type='Technology', properties={}), type='USES', properties={})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "추출된 노드: [Node(id='Apple', type='Company', properties={'industry': 'Technology'}), Node(id='Ios 18', type='Product', properties={'version': '18', 'releasedate': '2024-06', 'category': 'Mobile Operating System'}), Node(id='Apple Intelligence', type='Technology', properties={'category': 'Artificial Intelligence'}), Node(id='Gpt 기반 대형 언어 모델', type='Technology', properties={'category': 'Large Language Model'}), Node(id='온디바이스 Ai', type='Technology', properties={'category': 'On-device Artificial Intelligence'})]\n",
      "추출된 관계: [Relationship(source=Node(id='Apple', type='Company', properties={}), target=Node(id='Ios 18', type='Product', properties={}), type='RELEASED', properties={}), Relationship(source=Node(id='Apple', type='Company', properties={}), target=Node(id='Apple Intelligence', type='Technology', properties={}), type='DEVELOPED', properties={}), Relationship(source=Node(id='Ios 18', type='Product', properties={}), target=Node(id='Apple Intelligence', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='Ios 18', type='Product', properties={}), target=Node(id='Gpt 기반 대형 언어 모델', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='Ios 18', type='Product', properties={}), target=Node(id='온디바이스 Ai', type='Technology', properties={}), type='USES', properties={})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "추출된 노드: [Node(id='메타', type='Company', properties={'industry': 'AI'}), Node(id='Llama 3', type='Product', properties={'version': '3', 'category': 'AI 모델'}), Node(id='오픈소스', type='Technology', properties={}), Node(id='다국어 능력', type='Technology', properties={}), Node(id='코딩 능력', type='Technology', properties={})]\n",
      "추출된 관계: [Relationship(source=Node(id='메타', type='Company', properties={}), target=Node(id='Llama 3', type='Product', properties={}), type='RELEASED', properties={}), Relationship(source=Node(id='Llama 3', type='Product', properties={}), target=Node(id='오픈소스', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='Llama 3', type='Product', properties={}), target=Node(id='다국어 능력', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='Llama 3', type='Product', properties={}), target=Node(id='코딩 능력', type='Technology', properties={}), type='USES', properties={})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "추출된 노드: [Node(id='삼성전자', type='Company', properties={'industry': '반도체'}), Node(id='Ai 메모리', type='Product', properties={'category': '메모리 반도체'}), Node(id='컴퓨팅 인 메모리', type='Technology', properties={'category': 'AI 연산 최적화'}), Node(id='Hbm', type='Technology', properties={'category': 'High Bandwidth Memory'})]\n",
      "추출된 관계: [Relationship(source=Node(id='삼성전자', type='Company', properties={}), target=Node(id='Ai 메모리', type='Product', properties={}), type='RELEASED', properties={}), Relationship(source=Node(id='삼성전자', type='Company', properties={}), target=Node(id='컴퓨팅 인 메모리', type='Technology', properties={}), type='DEVELOPED', properties={}), Relationship(source=Node(id='Ai 메모리', type='Product', properties={}), target=Node(id='컴퓨팅 인 메모리', type='Technology', properties={}), type='USES', properties={}), Relationship(source=Node(id='Ai 메모리', type='Product', properties={}), target=Node(id='Hbm', type='Technology', properties={}), type='USES', properties={})]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "추출된 노드: [Node(id='엔비디아', type='Company', properties={'industry': 'AI 반도체'}), Node(id='H200', type='Product', properties={'category': 'AI 전용 GPU'}), Node(id='트랜스포머 엔진', type='Technology', properties={})]\n",
      "추출된 관계: [Relationship(source=Node(id='엔비디아', type='Company', properties={}), target=Node(id='H200', type='Product', properties={}), type='RELEASED', properties={}), Relationship(source=Node(id='H200', type='Product', properties={}), target=Node(id='트랜스포머 엔진', type='Technology', properties={}), type='USES', properties={})]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 추출된 그래프 데이터를 Neo4j 데이터베이스에 저장하는 과정\n",
    "# - 각 그래프 문서(doc)는 LLM이 뉴스 기사에서 추출한 구조화된 정보를 포함\n",
    "\n",
    "for doc in graph_documents:\n",
    "    # 디버깅 및 검증을 위해 각 문서에서 추출된 그래프 요소 출력\n",
    "    # - 노드: 회사, 기술, 제품 등의 개체 정보 (이름, 유형, 속성 등)\n",
    "    print(f\"추출된 노드: {doc.nodes}\")\n",
    "    \n",
    "    # - 관계: 노드 간의 연결 정보 (개발, 출시, 사용 등의 관계 유형)\n",
    "    print(f\"추출된 관계: {doc.relationships}\")\n",
    "    \n",
    "    # Neo4j 그래프 데이터베이스에 추출된 정보 저장\n",
    "    # - add_graph_documents: 그래프 문서를 Neo4j에 저장하는 메서드\n",
    "    # - [doc]: 단일 문서를 리스트 형태로 전달 (일괄 처리 가능)\n",
    "    # - include_source=True: 원본 문서 정보도 함께 저장 (추적성 유지)\n",
    "    graph.add_graph_documents([doc], include_source=True)\n",
    "    \n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789a5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 Document 노드 이름을 NewsArticle로 변경했습니다. 변경된 노드 수: 5\n"
     ]
    }
   ],
   "source": [
    "# Neo4j 데이터베이스에서 Document 노드 레이블을 NewsArticle로 변경하는 작업\n",
    "# - 그래프 데이터 모델의 일관성을 위해 Document 레이블을 NewsArticle로 변경\n",
    "# - 뉴스 기사 데이터의 특성을 더 명확하게 표현하기 위한 레이블 변경\n",
    "# - 이후 분석 및 쿼리 작업에서 뉴스 기사 노드를 더 직관적으로 참조 가능\n",
    "\n",
    "# Cypher 쿼리 정의:\n",
    "# - MATCH (d:Document): Document 레이블을 가진 모든 노드 선택\n",
    "# - SET d:NewsArticle: 선택된 노드에 NewsArticle 레이블 추가\n",
    "# - REMOVE d:Document: 기존 Document 레이블 제거\n",
    "# - RETURN count(d) AS count: 변경된 노드 수 반환\n",
    "cypher_query = \"\"\"\n",
    "MATCH (d:Document)\n",
    "SET d:NewsArticle\n",
    "REMOVE d:Document\n",
    "RETURN count(d) AS count\n",
    "\"\"\"\n",
    "\n",
    "# 정의된 Cypher 쿼리를 Neo4j 데이터베이스에 실행\n",
    "result = graph.query(cypher_query)\n",
    "\n",
    "# 변경 작업 결과 출력\n",
    "# - result[0]['count']: 쿼리 결과에서 변경된 노드 수 추출\n",
    "print(f\"모든 Document 노드 이름을 NewsArticle로 변경했습니다. 변경된 노드 수: {result[0]['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec167d",
   "metadata": {},
   "source": [
    "`(4) NewsArticle 관련 노드/관계 생성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408bafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "언론사 노드 수: 2\n"
     ]
    }
   ],
   "source": [
    "# 언론사를 Company 노드로 추가하는 Cypher 쿼리\n",
    "# - MATCH (n:NewsArticle): 모든 NewsArticle 노드를 찾음\n",
    "# - WITH DISTINCT n.source AS source: 중복 없이 뉴스 기사의 출처(언론사) 추출\n",
    "# - MERGE (c:Company {name: source, type: 'news'}): \n",
    "#   * 해당 이름의 Company 노드가 없으면 생성, 있으면 기존 노드 사용\n",
    "#   * name 속성에는 언론사 이름, type 속성에는 'news' 값 설정\n",
    "# - RETURN count(c) AS count: 생성 또는 매칭된 Company 노드 수 반환\n",
    "query = \"\"\"\n",
    "MATCH (n:NewsArticle)\n",
    "WITH DISTINCT n.source AS source\n",
    "MERGE (c:Company {name: source, type: 'news'})\n",
    "RETURN count(c) AS count\n",
    "\"\"\"\n",
    "# Neo4j 데이터베이스에 쿼리 실행\n",
    "result = graph.query(query)\n",
    "\n",
    "# 생성된 언론사 노드 수 출력\n",
    "print(f\"언론사 노드 수: {result[0]['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de73305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 기사와 언론사 노드 연결 수: 5\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 기사와 언론사 노드 연결하는 Cypher 쿼리\n",
    "# - MATCH (n:NewsArticle), (c:Company): NewsArticle 노드와 Company 노드를 각각 찾음\n",
    "# - WHERE n.source = c.name: 뉴스 기사의 source 속성이 회사의 name 속성과 일치하는 경우 필터링\n",
    "# - MERGE (n)-[:PUBLISHED_BY]->(c): 뉴스 기사에서 언론사로 향하는 PUBLISHED_BY 관계 생성\n",
    "#   * 관계가 이미 존재하면 기존 관계 사용, 없으면 새로 생성\n",
    "# - RETURN count(n) AS count: 관계가 생성된 뉴스 기사 노드의 수를 반환\n",
    "query = \"\"\"\n",
    "MATCH (n:NewsArticle), (c:Company)\n",
    "WHERE n.source = c.name\n",
    "MERGE (n)-[:PUBLISHED_BY]->(c)\n",
    "RETURN count(n) AS count\n",
    "\"\"\"\n",
    "# Neo4j 데이터베이스에 쿼리 실행\n",
    "result = graph.query(query)\n",
    "# 생성된 관계 수 출력\n",
    "print(f\"뉴스 기사와 언론사 노드 연결 수: {result[0]['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e876afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기자 노드 수: 5\n"
     ]
    }
   ],
   "source": [
    "# 기자를 Person 노드로 추가하고, 뉴스 기사 노드와 언론사 노드와 연결하는 Cypher 쿼리\n",
    "query = \"\"\"\n",
    "// 모든 뉴스 기사 노드를 찾음\n",
    "MATCH (n:NewsArticle)\n",
    "\n",
    "// 중복 없이 기자(author), 언론사(source), 기사ID를 추출\n",
    "WITH DISTINCT n.author AS author, n.source AS source, n.id AS articleId\n",
    "\n",
    "// 기자 노드 생성 (없으면 생성, 있으면 기존 노드 사용)\n",
    "// MERGE: 노드가 존재하지 않으면 생성하고, 존재하면 매칭함\n",
    "MERGE (p:Person {name: author})\n",
    "\n",
    "// 이전 단계에서 생성한 기자 노드(p)와 언론사 정보, 기사ID를 다음 단계로 전달\n",
    "WITH p, source, articleId\n",
    "\n",
    "// 언론사 노드 생성 또는 매칭\n",
    "MERGE (c:Company {name: source})\n",
    "\n",
    "// 기자와 언론사 사이에 WORKS_FOR 관계 생성\n",
    "MERGE (p)-[:WORKS_FOR]->(c)\n",
    "\n",
    "// 기자 노드와 기사ID를 다음 단계로 전달\n",
    "WITH p, articleId\n",
    "\n",
    "// 해당 ID를 가진 뉴스 기사 노드 찾기\n",
    "MATCH (a:NewsArticle {id: articleId})\n",
    "\n",
    "// 기자와 뉴스 기사 사이에 WROTE 관계 생성\n",
    "MERGE (p)-[:WROTE]->(a)\n",
    "\n",
    "// 생성된 고유한 기자 노드의 수를 반환\n",
    "// count(DISTINCT p): 중복 없이 기자 노드 수를 계산\n",
    "RETURN count(DISTINCT p) AS count\n",
    "\"\"\"\n",
    "\n",
    "# Neo4j 데이터베이스에 쿼리 실행\n",
    "result = graph.query(query)\n",
    "\n",
    "# 생성된 기자 노드 수 출력\n",
    "print(f\"기자 노드 수: {result[0]['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c908226",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. **쿼리를 이용한 뉴스 데이터 분석**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923ac76",
   "metadata": {},
   "source": [
    "### 3.1 cypher 구문 직접 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54885f5c",
   "metadata": {},
   "source": [
    "#### 1) **스키마 정보 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00598adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **NewsArticle**\n",
      "  - `id`: STRING Available options: ['article_0', 'article_1', 'article_2', 'article_3', 'article_4']\n",
      "  - `text`: STRING Available options: ['구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고 발표했다. 이번 발표는 구글의', '애플이 차세대 모바일 운영체제 iOS 18을 공개하며 AI 플랫폼 경쟁을 본격화하고 있다.', \"메타가 차세대 오픈소스 AI 모델 'Llama 3'를 공개했다. 이번 모델은 이전 버전보다\", \"삼성전자가 AI 연산에 최적화된 '컴퓨팅 인 메모리'(CIM) 기술을 적용한 신개념 메모리\", \"엔비디아가 차세대 AI 전용 GPU 'H200'의 출시가 임박했다고 발표했다. 이번 신제품\"]\n",
      "  - `date`: STRING Available options: ['2024-03-20', '2024-03-19', '2024-04-05', '2024-04-03', '2024-04-02']\n",
      "  - `source`: STRING Available options: ['디지털타임스', '전자일보']\n",
      "  - `title`: STRING Available options: ['구글, 안드로이드 14에 생성형 AI 기능 대거 탑재', '애플, iOS 18 공개하며 AI 플랫폼 경쟁 본격화', \"메타, 차세대 오픈소스 AI 모델 'Llama 3' 공개\", \"삼성전자, 'AI 메모리' 신기술 개발 성공\", \"엔비디아, 차세대 AI 전용 GPU 'H200' 출시 임박\"]\n",
      "  - `author`: STRING Available options: ['박승리', '최기상', '정주리', '이승지', '김송이']\n",
      "- **Company**\n",
      "  - `id`: STRING Available options: ['구글', 'Apple', '메타', '삼성전자', '엔비디아']\n",
      "  - `industry`: STRING Available options: ['technology', 'Technology', 'AI', '반도체', 'AI 반도체']\n",
      "  - `name`: STRING Available options: ['디지털타임스', '전자일보']\n",
      "  - `type`: STRING Available options: ['news']\n",
      "- **Product**\n",
      "  - `id`: STRING Available options: ['안드로이드 14', '구글 어시스턴트', 'Ios 18', 'Llama 3', 'Ai 메모리', 'H200']\n",
      "  - `category`: STRING Available options: ['mobile operating system', 'virtual assistant', 'Mobile Operating System', 'AI 모델', '메모리 반도체', 'AI 전용 GPU']\n",
      "  - `version`: STRING Available options: ['14', '18', '3']\n",
      "  - `releasedate`: STRING Available options: ['2024-06']\n",
      "- **Technology**\n",
      "  - `id`: STRING Example: \"생성형 Ai\"\n",
      "  - `category`: STRING Available options: ['artificial intelligence', 'image processing', 'translation', 'speech translation', 'Artificial Intelligence', 'Large Language Model', 'On-device Artificial Intelligence', 'AI 연산 최적화', 'High Bandwidth Memory']\n",
      "- **Person**\n",
      "  - `name`: STRING Available options: ['박승리', '최기상', '정주리', '이승지', '김송이']\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:NewsArticle)-[:MENTIONS]->(:Company)\n",
      "(:NewsArticle)-[:MENTIONS]->(:Product)\n",
      "(:NewsArticle)-[:MENTIONS]->(:Technology)\n",
      "(:NewsArticle)-[:PUBLISHED_BY]->(:Company)\n",
      "(:Company)-[:RELEASED]->(:Product)\n",
      "(:Company)-[:DEVELOPED]->(:Technology)\n",
      "(:Product)-[:USES]->(:Technology)\n",
      "(:Person)-[:WORKS_FOR]->(:Company)\n",
      "(:Person)-[:WROTE]->(:NewsArticle)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04f5d5",
   "metadata": {},
   "source": [
    "#### 2) **기업 및 제품 언론 보도 분석**\n",
    "\n",
    "- 목적: 기업과 제품의 미디어 노출 정도 측정\n",
    "- 유용성: PR 및 마케팅 효과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c70bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글: 1회\n",
      "Apple: 1회\n",
      "메타: 1회\n",
      "삼성전자: 1회\n",
      "엔비디아: 1회\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 기사에서 특정 기업의 멘션 횟수 분석\n",
    "# 목적: 각 기업이 뉴스 기사에서 언급된 횟수를 계산하여 미디어 노출도 측정\n",
    "# 방법: NewsArticle과 Company 노드 간의 MENTIONS 관계를 통해 연결 분석\n",
    "query = \"\"\"\n",
    "// 뉴스 기사에서 기업 언급 횟수 분석\n",
    "// MATCH: NewsArticle 노드와 Company 노드 간의 MENTIONS 관계 찾기\n",
    "MATCH (n:NewsArticle)-[:MENTIONS]->(c:Company)\n",
    "\n",
    "// WITH: 각 기업별로 그룹화하여 언급 횟수 계산\n",
    "WITH c.id AS companyName, COUNT(n) AS mentionCount\n",
    "\n",
    "// RETURN: 기업명과 언급 횟수 반환\n",
    "RETURN companyName, mentionCount\n",
    "\n",
    "// ORDER BY: 언급 횟수 기준 내림차순 정렬\n",
    "ORDER BY mentionCount DESC  \n",
    "\"\"\"\n",
    "\n",
    "# Neo4j 데이터베이스에 쿼리 실행하여 결과 가져오기\n",
    "result = graph.query(query)\n",
    "\n",
    "# 각 기업명과 해당 기업이 언급된 기사 수를 내림차순으로 표시\n",
    "for record in result:\n",
    "    print(f\"{record['companyName']}: {record['mentionCount']}회\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bac197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안드로이드 14: 1회\n",
      "구글 어시스턴트: 1회\n",
      "Ios 18: 1회\n",
      "Llama 3: 1회\n",
      "Ai 메모리: 1회\n",
      "H200: 1회\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 기사에서 특정 제품의 멘션 횟수 분석\n",
    "# 목적: 각 제품이 뉴스 기사에서 언급된 횟수를 계산하여 제품의 미디어 노출도 측정\n",
    "# 방법: NewsArticle과 Product 노드 간의 MENTIONS 관계를 통해 연결 분석\n",
    "query = \"\"\"\n",
    "// 뉴스 기사에서 제품 언급 횟수 분석\n",
    "// MATCH: NewsArticle 노드와 Product 노드 간의 MENTIONS 관계 찾기\n",
    "MATCH (n:NewsArticle)-[:MENTIONS]->(p:Product)\n",
    "\n",
    "// WITH: 각 제품별로 그룹화하여 언급 횟수 계산\n",
    "WITH p.id AS productName, COUNT(n) AS mentionCount\n",
    "\n",
    "// RETURN: 제품명과 언급 횟수 반환\n",
    "RETURN productName, mentionCount\n",
    "\n",
    "// ORDER BY: 언급 횟수 기준 내림차순 정렬\n",
    "ORDER BY mentionCount DESC  \n",
    "\"\"\"\n",
    "# Neo4j 데이터베이스에 쿼리 실행하여 결과 가져오기\n",
    "result = graph.query(query)\n",
    "\n",
    "# 각 제품명과 해당 제품이 언급된 기사 수를 내림차순으로 표시\n",
    "for record in result:\n",
    "    print(f\"{record['productName']}: {record['mentionCount']}회\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a1072",
   "metadata": {},
   "source": [
    "#### 3) **뉴스 기사에서 언급된 기술 순위**\n",
    "\n",
    "- 목적: 미디어에서 가장 많이 언급되는 기술 파악\n",
    "- 유용성: 기술 트렌드 및 미디어 관심도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진 보정 기능: 1회\n",
      "실시간 번역 기능: 1회\n",
      "실시간 음성 번역 기능: 1회\n",
      "Apple Intelligence: 1회\n",
      "생성형 Ai: 1회\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 기사에서 특정 기술의 멘션 횟수 분석\n",
    "# 목적: 각 기술이 뉴스 기사에서 언급된 횟수를 계산하여 기술의 미디어 노출도 측정\n",
    "# 방법: NewsArticle과 Technology 노드 간의 MENTIONS 관계를 통해 연결 분석\n",
    "query = \"\"\"\n",
    "// 뉴스 기사에서 기술 언급 횟수 분석\n",
    "// MATCH: NewsArticle 노드와 Technology 노드 간의 MENTIONS 관계 찾기\n",
    "MATCH (n:NewsArticle)-[:MENTIONS]->(t:Technology)\n",
    "\n",
    "// RETURN: 기술 ID와 해당 기술을 언급한 고유 뉴스 기사 수 반환\n",
    "RETURN t.id, COUNT(DISTINCT n) AS news_coverage\n",
    "\n",
    "// ORDER BY: 뉴스 기사 수 기준 내림차순 정렬\n",
    "ORDER BY news_coverage DESC\n",
    "\n",
    "// LIMIT: 상위 5개 결과만 표시\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "# Neo4j 데이터베이스에 쿼리 실행하여 결과 가져오기\n",
    "result = graph.query(query)\n",
    "\n",
    "# 각 기술과 해당 기술이 언급된 기사 수를 내림차순으로 표시\n",
    "for record in result:\n",
    "    print(f\"{record['t.id']}: {record['news_coverage']}회\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d4fae",
   "metadata": {},
   "source": [
    "#### 4) **기업별 뉴스 작성자 식별**\n",
    "\n",
    "- 목적: 기업별 뉴스 작성자 파악\n",
    "- 유용성: 미디어 관계 및 보도 패턴 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글의 저자: 박승리 (총 기사 수: 1)\n",
      "Apple의 저자: 최기상 (총 기사 수: 1)\n",
      "메타의 저자: 정주리 (총 기사 수: 1)\n",
      "삼성전자의 저자: 이승지 (총 기사 수: 1)\n",
      "엔비디아의 저자: 김송이 (총 기사 수: 1)\n"
     ]
    }
   ],
   "source": [
    "# 특정 기업에 대해 글을 쓴 저자 조회\n",
    "# 목적: 각 기업을 언급한 뉴스 기사의 작성자를 식별하고 기사 수를 계산\n",
    "# 방법: NewsArticle-MENTIONS->Company와 Person-WROTE->NewsArticle 관계를 함께 분석\n",
    "query = \"\"\"\n",
    "// 기업과 기사 관계 조회\n",
    "// MATCH: NewsArticle 노드와 Company 노드 간의 MENTIONS 관계 찾기\n",
    "// MATCH: NewsArticle 노드와 Person 노드 간의 WROTE 관계 찾기\n",
    "MATCH (n:NewsArticle)-[:MENTIONS]->(c:Company), \n",
    "      (n)<-[:WROTE]-(person:Person)\n",
    "\n",
    "// RETURN: 기업명, 작성자 목록, 기사 수 반환\n",
    "RETURN c.id AS companyName,    // 기업명\n",
    "       COLLECT(DISTINCT person.name) AS authors,   // 작성자 목록 (중복 제거)\n",
    "       COUNT(DISTINCT n) AS article_count          // 기사 수 (중복 제거)\n",
    "\n",
    "// ORDER BY: 기사 수 기준 내림차순 정렬\n",
    "ORDER BY article_count DESC\n",
    "\"\"\"\n",
    "\n",
    "# Neo4j 데이터베이스에 쿼리 실행하여 결과 가져오기\n",
    "result = graph.query(query)\n",
    "\n",
    "# 저자 조회 결과 출력\n",
    "# 각 기업별로 해당 기업을 언급한 기사의 작성자 목록과 총 기사 수를 표시\n",
    "for record in result:\n",
    "    authors = record['authors']\n",
    "    authors_str = ', '.join(authors)  # 작성자 목록을 쉼표로 구분하여 문자열로 변환\n",
    "    print(f\"{record['companyName']}의 저자: {authors_str} (총 기사 수: {record['article_count']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57430f",
   "metadata": {},
   "source": [
    "#### 5) **기업과 보유 기술 조회**\n",
    "\n",
    "- 목적: 각 기업이 개발한 기술 목록을 확인\n",
    "- 유용성: 기업의 기술 포트폴리오 파악에 도움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08511d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글이 개발한 기술: 생성형 Ai\n",
      "Apple이 개발한 기술: Apple Intelligence\n",
      "삼성전자이 개발한 기술: 컴퓨팅 인 메모리\n"
     ]
    }
   ],
   "source": [
    "# 각 기업이 개발한 기술을 조회하는 쿼리\n",
    "# 목적: 기업과 기술 간의 관계를 파악하여 각 기업의 기술 포트폴리오 확인\n",
    "# 방법: Company-DEVELOPED->Technology 관계를 통해 기업이 개발한 기술 목록 추출\n",
    "query = \"\"\"\n",
    "// 기업과 기술 관계 조회\n",
    "// MATCH: Company 노드와 Technology 노드 간의 DEVELOPED 관계 찾기\n",
    "MATCH (c:Company)-[:DEVELOPED]->(t:Technology)\n",
    "\n",
    "// RETURN: 기업명과 기술 목록 반환\n",
    "RETURN c.id AS companyName, COLLECT(t.id) AS technologies\n",
    "\"\"\"\n",
    "\n",
    "# Neo4j 데이터베이스에 쿼리 실행하여 결과 가져오기\n",
    "result = graph.query(query)\n",
    "\n",
    "# 기업과 기술 관계 결과 출력\n",
    "# 각 기업별로 해당 기업이 개발한 모든 기술을 쉼표로 구분하여 표시\n",
    "for record in result:\n",
    "    technologies = record['technologies']\n",
    "    technologies_str = ', '.join(technologies)  # 기술 목록을 쉼표로 구분하여 문자열로 변환\n",
    "    print(f\"{record['companyName']}이 개발한 기술: {technologies_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d762e3",
   "metadata": {},
   "source": [
    "### 3.2 그래프 검색을 위해 **Text2cypher** 사용\n",
    "\n",
    "- LangChain으로 Neo4J 지식 그래프 조회\n",
    "- https://python.langchain.com/docs/integrations/graphs/neo4j_cypher/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0be3c2",
   "metadata": {},
   "source": [
    "#### 1) **스키마 정보 확인**\n",
    "\n",
    "- LLM이 Cypher 쿼리를 생성하려면 그래프 데이터베이스의 스키마 정보가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **NewsArticle**\n",
      "  - `id`: STRING Available options: ['article_0', 'article_1', 'article_2', 'article_3', 'article_4']\n",
      "  - `text`: STRING Available options: ['구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고 발표했다. 이번 발표는 구글의', '애플이 차세대 모바일 운영체제 iOS 18을 공개하며 AI 플랫폼 경쟁을 본격화하고 있다.', \"메타가 차세대 오픈소스 AI 모델 'Llama 3'를 공개했다. 이번 모델은 이전 버전보다\", \"삼성전자가 AI 연산에 최적화된 '컴퓨팅 인 메모리'(CIM) 기술을 적용한 신개념 메모리\", \"엔비디아가 차세대 AI 전용 GPU 'H200'의 출시가 임박했다고 발표했다. 이번 신제품\"]\n",
      "  - `date`: STRING Available options: ['2024-03-20', '2024-03-19', '2024-04-05', '2024-04-03', '2024-04-02']\n",
      "  - `source`: STRING Available options: ['디지털타임스', '전자일보']\n",
      "  - `title`: STRING Available options: ['구글, 안드로이드 14에 생성형 AI 기능 대거 탑재', '애플, iOS 18 공개하며 AI 플랫폼 경쟁 본격화', \"메타, 차세대 오픈소스 AI 모델 'Llama 3' 공개\", \"삼성전자, 'AI 메모리' 신기술 개발 성공\", \"엔비디아, 차세대 AI 전용 GPU 'H200' 출시 임박\"]\n",
      "  - `author`: STRING Available options: ['박승리', '최기상', '정주리', '이승지', '김송이']\n",
      "- **Company**\n",
      "  - `id`: STRING Available options: ['구글', 'Apple', '메타', '삼성전자', '엔비디아']\n",
      "  - `industry`: STRING Available options: ['technology', 'Technology', 'AI', '반도체', 'AI 반도체']\n",
      "  - `name`: STRING Available options: ['디지털타임스', '전자일보']\n",
      "  - `type`: STRING Available options: ['news']\n",
      "- **Product**\n",
      "  - `id`: STRING Available options: ['안드로이드 14', '구글 어시스턴트', 'Ios 18', 'Llama 3', 'Ai 메모리', 'H200']\n",
      "  - `category`: STRING Available options: ['mobile operating system', 'virtual assistant', 'Mobile Operating System', 'AI 모델', '메모리 반도체', 'AI 전용 GPU']\n",
      "  - `version`: STRING Available options: ['14', '18', '3']\n",
      "  - `releasedate`: STRING Available options: ['2024-06']\n",
      "- **Technology**\n",
      "  - `id`: STRING Example: \"생성형 Ai\"\n",
      "  - `category`: STRING Available options: ['artificial intelligence', 'image processing', 'translation', 'speech translation', 'Artificial Intelligence', 'Large Language Model', 'On-device Artificial Intelligence', 'AI 연산 최적화', 'High Bandwidth Memory']\n",
      "- **Person**\n",
      "  - `name`: STRING Available options: ['박승리', '최기상', '정주리', '이승지', '김송이']\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:NewsArticle)-[:MENTIONS]->(:Company)\n",
      "(:NewsArticle)-[:MENTIONS]->(:Product)\n",
      "(:NewsArticle)-[:MENTIONS]->(:Technology)\n",
      "(:NewsArticle)-[:PUBLISHED_BY]->(:Company)\n",
      "(:Company)-[:RELEASED]->(:Product)\n",
      "(:Company)-[:DEVELOPED]->(:Technology)\n",
      "(:Product)-[:USES]->(:Technology)\n",
      "(:Person)-[:WORKS_FOR]->(:Company)\n",
      "(:Person)-[:WROTE]->(:NewsArticle)\n"
     ]
    }
   ],
   "source": [
    "# 기본 스키마 정보 확인\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8149398e",
   "metadata": {},
   "source": [
    "#### 2) **GraphCypherQAChain 설정**\n",
    "\n",
    "- `GraphCypherQAChain`은 LangChain에서 제공하는 체인으로, 자연어 질문을 Cypher 쿼리로 변환하고 그 결과를 바탕으로 답변을 생성\n",
    "\n",
    "- 작동 과정:\n",
    "    1. 사용자의 자연어 질문 입력\n",
    "    2. LLM을 사용하여 질문을 Cypher 쿼리로 변환\n",
    "    3. 생성된 Cypher 쿼리를 Neo4j 데이터베이스에 실행\n",
    "    4. 쿼리 결과를 LLM에 전달하여 자연어 답변 생성\n",
    "\n",
    "- 주요 구성 요소\n",
    "    - `cypher_generation_chain`: 자연어를 Cypher 쿼리로 변환하는 체인\n",
    "    - `qa_chain`: 쿼리 결과를 바탕으로 답변을 생성하는 체인\n",
    "    - `graph`: Neo4j 그래프 데이터베이스 연결 객체\n",
    "    - `graph_schema`: 그래프 데이터베이스의 스키마 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c513e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import GraphCypherQAChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "\n",
    "# LLM 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "\n",
    "# GraphCypherQAChain 생성\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph,  \n",
    "    validate_cypher=True,            # Cypher 쿼리 유효성 검사\n",
    "    return_intermediate_steps=True,  # 중간 단계 결과 반환\n",
    "    allow_dangerous_requests=True,   # DB에 영향을 줄 수 있음을 인지하고 쿼리 실행을 허용\n",
    "    top_k=5                          # 반환할 최대 결과 수\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e5cb0",
   "metadata": {},
   "source": [
    "#### 3) **Text to Cypher - DB 조회**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcaa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_query = \"\"\"\n",
    "// Company 노드 중 id 속성이 있는 노드 찾기\n",
    "MATCH (c:Company)\n",
    "WHERE c.id IS NOT NULL AND c.name IS NULL\n",
    "\n",
    "// id 값을 name 속성으로 복사하고 id 속성 삭제\n",
    "SET c.name = c.id\n",
    "REMOVE c.id\n",
    "\n",
    "RETURN count(c) AS updated_companies\n",
    "\"\"\"\n",
    "\n",
    "# Cypher 쿼리 실행\n",
    "result = graph.query(cypher_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ef963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'updated_companies': 5}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed2b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **NewsArticle**\n",
      "  - `id`: STRING Available options: ['article_0', 'article_1', 'article_2', 'article_3', 'article_4']\n",
      "  - `text`: STRING Available options: ['구글이 안드로이드 14에 생성형 AI 기능을 대거 탑재했다고 발표했다. 이번 발표는 구글의', '애플이 차세대 모바일 운영체제 iOS 18을 공개하며 AI 플랫폼 경쟁을 본격화하고 있다.', \"메타가 차세대 오픈소스 AI 모델 'Llama 3'를 공개했다. 이번 모델은 이전 버전보다\", \"삼성전자가 AI 연산에 최적화된 '컴퓨팅 인 메모리'(CIM) 기술을 적용한 신개념 메모리\", \"엔비디아가 차세대 AI 전용 GPU 'H200'의 출시가 임박했다고 발표했다. 이번 신제품\"]\n",
      "  - `date`: STRING Available options: ['2024-03-20', '2024-03-19', '2024-04-05', '2024-04-03', '2024-04-02']\n",
      "  - `source`: STRING Available options: ['디지털타임스', '전자일보']\n",
      "  - `title`: STRING Available options: ['구글, 안드로이드 14에 생성형 AI 기능 대거 탑재', '애플, iOS 18 공개하며 AI 플랫폼 경쟁 본격화', \"메타, 차세대 오픈소스 AI 모델 'Llama 3' 공개\", \"삼성전자, 'AI 메모리' 신기술 개발 성공\", \"엔비디아, 차세대 AI 전용 GPU 'H200' 출시 임박\"]\n",
      "  - `author`: STRING Available options: ['박승리', '최기상', '정주리', '이승지', '김송이']\n",
      "- **Company**\n",
      "  - `name`: STRING Available options: ['구글', 'Apple', '메타', '삼성전자', '엔비디아', '디지털타임스', '전자일보']\n",
      "  - `industry`: STRING Available options: ['technology', 'Technology', 'AI', '반도체', 'AI 반도체']\n",
      "  - `type`: STRING Available options: ['news']\n",
      "- **Product**\n",
      "  - `id`: STRING Available options: ['안드로이드 14', '구글 어시스턴트', 'Ios 18', 'Llama 3', 'Ai 메모리', 'H200']\n",
      "  - `category`: STRING Available options: ['mobile operating system', 'virtual assistant', 'Mobile Operating System', 'AI 모델', '메모리 반도체', 'AI 전용 GPU']\n",
      "  - `version`: STRING Available options: ['14', '18', '3']\n",
      "  - `releasedate`: STRING Available options: ['2024-06']\n",
      "- **Technology**\n",
      "  - `id`: STRING Example: \"생성형 Ai\"\n",
      "  - `category`: STRING Available options: ['artificial intelligence', 'image processing', 'translation', 'speech translation', 'Artificial Intelligence', 'Large Language Model', 'On-device Artificial Intelligence', 'AI 연산 최적화', 'High Bandwidth Memory']\n",
      "- **Person**\n",
      "  - `name`: STRING Available options: ['박승리', '최기상', '정주리', '이승지', '김송이']\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:NewsArticle)-[:MENTIONS]->(:Company)\n",
      "(:NewsArticle)-[:MENTIONS]->(:Product)\n",
      "(:NewsArticle)-[:MENTIONS]->(:Technology)\n",
      "(:NewsArticle)-[:PUBLISHED_BY]->(:Company)\n",
      "(:Company)-[:RELEASED]->(:Product)\n",
      "(:Company)-[:DEVELOPED]->(:Technology)\n",
      "(:Product)-[:USES]->(:Technology)\n",
      "(:Person)-[:WORKS_FOR]->(:Company)\n",
      "(:Person)-[:WROTE]->(:NewsArticle)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()  # 스키마 새로 고침\n",
    "print(graph.schema)  # 스키마 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcypher_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m엔비디아를 언급한 기사는 몇 개인가요?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_neo4j\\chains\\graph_qa\\cypher.py:391\u001b[39m, in \u001b[36mGraphCypherQAChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    387\u001b[39m args.update(inputs)\n\u001b[32m    389\u001b[39m intermediate_steps: List = []\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m generated_cypher = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcypher_generation_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# Extract Cypher code if it is wrapped in backticks\u001b[39;00m\n\u001b[32m    396\u001b[39m generated_cypher = extract_cypher(generated_cypher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3254\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3252\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3253\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3254\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3255\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5720\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5713\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5714\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5715\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5718\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5719\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5721\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5723\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1676\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1673\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1676\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     **kwargs: Any,\n\u001b[32m   1023\u001b[39m ) -> LLMResult:\n\u001b[32m   1024\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1790\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:238\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    231\u001b[39m params = (\n\u001b[32m    232\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cypher_chain.invoke({\"query\": \"엔비디아를 언급한 기사는 몇 개인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f132f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcypher_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m가장 많은 기사를 작성한 언론사는 어디인가요?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_neo4j\\chains\\graph_qa\\cypher.py:391\u001b[39m, in \u001b[36mGraphCypherQAChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    387\u001b[39m args.update(inputs)\n\u001b[32m    389\u001b[39m intermediate_steps: List = []\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m generated_cypher = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcypher_generation_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# Extract Cypher code if it is wrapped in backticks\u001b[39;00m\n\u001b[32m    396\u001b[39m generated_cypher = extract_cypher(generated_cypher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3254\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3252\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3253\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3254\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3255\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5720\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5713\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5714\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5715\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5718\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5719\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5721\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5722\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5723\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1676\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1673\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1676\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     **kwargs: Any,\n\u001b[32m   1023\u001b[39m ) -> LLMResult:\n\u001b[32m   1024\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1790\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:238\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    231\u001b[39m params = (\n\u001b[32m    232\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\neo4j_project\\neo4j_graph_rag\\.venv\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cypher_chain.invoke({\"query\": \"가장 많은 기사를 작성한 언론사는 어디인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177db1ba",
   "metadata": {},
   "source": [
    "#### 4) **직접 Cypher 결과 얻기 (LLM 답변 없이)** \n",
    "\n",
    "- `return_direct`=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7637ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. .\n"
     ]
    }
   ],
   "source": [
    "# 직접 Cypher 결과 얻기 (LLM 답변 없이)\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph, \n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True,\n",
    "    return_direct=True  # LLM 답변 생성 단계 건너뛰기\n",
    ")\n",
    "\n",
    "# 각 언론사별로 작성한 기사의 개수를 추출\n",
    "cypher_chain.invoke({\"query\": \"각 언론사별로 몇 개의 뉴스를 작성했나요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310fbb2",
   "metadata": {},
   "source": [
    "### 3.3 Graph RAG 구현\n",
    "\n",
    "- 뉴스 본문을 위한 **벡터 인덱스**를 기존 노트북에 추가\n",
    "- **벡터 임베딩** 생성 및 Neo4j 저장 기능 구현함\n",
    "- **벡터 유사도 검색**과 **지식 그래프 결합** 하이브리드 검색 구현\n",
    "- 기본 **RAG 시스템**과 지식 그래프로 **강화된 RAG 시스템** 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b522f3b1",
   "metadata": {},
   "source": [
    "#### 1) **벡터 임베딩 모델** 설정\n",
    "\n",
    "- 뉴스 본문의 벡터화 및 저장을 위한 기초 작업\n",
    "- 임베딩 모델 설정은 벡터 검색 성능에 직접적 영향을 미침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a168b8b",
   "metadata": {},
   "source": [
    "#### 2) **벡터 인덱스** 생성\n",
    "\n",
    "- **news_content_embeddings**라는 이름의 벡터 인덱스를 NewsArticle 노드의 **content_embedding** 필드에 적용함 (필드를 새로 추가)\n",
    "- 벡터 차원을 **1536차원**으로 설정하여 OpenAI의 text-embedding-3-small 모델과 호환되도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b93e98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      2\u001b[39m create_vector_index_query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mCREATE VECTOR INDEX news_content_embeddings IF NOT EXISTS\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mFOR (n:NewsArticle)\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33m}}\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 벡터 인덱스 생성 쿼리 실행\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mgraph\u001b[49m.query(create_vector_index_query)\n",
      "\u001b[31mNameError\u001b[39m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "# 벡터 인덱스 생성\n",
    "create_vector_index_query = \"\"\"\n",
    "CREATE VECTOR INDEX news_content_embeddings IF NOT EXISTS\n",
    "FOR (n:NewsArticle)\n",
    "ON n.content_embedding\n",
    "OPTIONS {indexConfig: {\n",
    "  `vector.dimensions`: 1536,\n",
    "  `vector.similarity_function`: 'cosine'\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# 벡터 인덱스 생성 쿼리 실행\n",
    "graph.query(create_vector_index_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25180aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 인덱스 확인\n",
    "check_vector_index_query = \"\"\"\n",
    "SHOW VECTOR INDEXES\n",
    "\"\"\"\n",
    "vector_indexes = graph.query(check_vector_index_query)\n",
    "for index in vector_indexes:\n",
    "    # 벡터 인덱스 정보 출력\n",
    "    print(f\"Index Name: {index['name']}\")\n",
    "    print(f\"Type: {index['type']}\")    \n",
    "    print(f\"Property Key: {index['properties']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7a35e",
   "metadata": {},
   "source": [
    "#### 3) **임베딩 생성 및 저장**\n",
    "\n",
    "- 뉴스 텍스트에 대해 **OpenAI 임베딩**을 생성하는 과정 수행\n",
    "- 빈 문자열인 경우 처리를 **건너뛰는** 예외 처리 포함\n",
    "- 생성된 임베딩을 `db.create.setNodeVectorProperty` 프로시저를 통해 **content_embedding** 속성으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476735b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 기사 데이터 가져오기\n",
    "news_query = \"\"\"\n",
    "// 뉴스 기사 데이터 가져오기\n",
    "// MATCH: NewsArticle 노드 조회\n",
    "// WHERE: 뉴스 기사 내용이 NULL이 아닌 경우 필터링\n",
    "// RETURN: 기사 ID, 제목, 내용 반환\n",
    "MATCH (n:NewsArticle)\n",
    "WHERE n.text IS NOT NULL\n",
    "RETURN n.id AS id, n.title AS title, n.text AS text\n",
    "\"\"\"\n",
    "news_articles = graph.query(news_query)\n",
    "\n",
    "# 배치 크기 설정\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# 임베딩 생성 및 저장 (배치 처리)\n",
    "for i in range(0, len(news_articles), BATCH_SIZE):\n",
    "    batch = news_articles[i:i+BATCH_SIZE]\n",
    "    batch_texts = []\n",
    "    batch_ids = []\n",
    "    \n",
    "    # 배치 데이터 준비\n",
    "    for article in batch:\n",
    "        content_text = f\"{article['title']}\\n\\n{article['text']}\"\n",
    "        if content_text.strip(): # 빈 문자열 확인\n",
    "            batch_texts.append(content_text)\n",
    "            batch_ids.append(article['id'])\n",
    "    \n",
    "    try:\n",
    "        if batch_texts:\n",
    "            # 배치 단위로 OpenAI 임베딩 생성\n",
    "            batch_embeddings = embeddings.embed_documents(batch_texts)\n",
    "            \n",
    "            # UNWIND를 사용한 배치 업데이트\n",
    "            batch_data = [{\"id\": article_id, \"embedding\": embedding_vector} \n",
    "                         for article_id, embedding_vector in zip(batch_ids, batch_embeddings)]\n",
    "            \n",
    "            batch_update_query = \"\"\"\n",
    "            // 각 기사의 벡터 임베딩 업데이트\n",
    "            // UNWIND: 배치 데이터 반복 처리\n",
    "            // MATCH: NewsArticle 노드 조회\n",
    "            // CALL: db.create.setNodeVectorProperty 프로시저 호출\n",
    "            // RETURN: 업데이트된 기사 수 반환\n",
    "            UNWIND $batch AS item\n",
    "            MATCH (n:NewsArticle {id: item.id})\n",
    "            CALL db.create.setNodeVectorProperty(n, 'content_embedding', item.embedding)\n",
    "            RETURN count(n) as updated\n",
    "            \"\"\"\n",
    "            \n",
    "            result = graph.query(batch_update_query, params={\"batch\": batch_data})\n",
    "            print(f\"배치 처리 완료: {i+1}~{min(i+len(batch_texts), len(news_articles))} / {len(news_articles)}, 업데이트됨: {result[0]['updated']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"배치 임베딩 생성 실패 (배치 인덱스 {i}): {str(e)}\")\n",
    "\n",
    "print(f\"뉴스 기사 임베딩 업데이트 완료!! 총 {len(news_articles)}개 처리\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130c3e9a",
   "metadata": {},
   "source": [
    "#### 4) **Neo4j Graph DB 초기화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_neo4j import Neo4jVector\n",
    "import os\n",
    "\n",
    "# 임베딩 모델 설정 (인덱싱했던 모델과 동일)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\") \n",
    "\n",
    "# Neo4j 데이터베이스에 이미 생성된 벡터 인덱스에 연결하는 Neo4jVector 인스턴스 생성\n",
    "vector_store = Neo4jVector.from_existing_index(\n",
    "    embeddings,  # 사용할 임베딩 모델 지정\n",
    "    url=os.getenv(\"NEO4J_URI\"),  # Neo4j 데이터베이스 연결 URI (환경 변수에서 가져옴)\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),  # Neo4j 데이터베이스 사용자 이름\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),  # Neo4j 데이터베이스 비밀번호\n",
    "    database=os.getenv(\"NEO4J_DATABASE\"),  # Neo4j 데이터베이스 이름\n",
    "    index_name=\"news_content_embeddings\",  # 뉴스 기사용 벡터 인덱스 이름\n",
    "    node_label=\"NewsArticle\",  # 뉴스 기사 노드 레이블\n",
    "    text_node_property=\"text\",  # 텍스트 검색 시 반환할 노드의 속성 (뉴스 내용)\n",
    "    embedding_node_property=\"content_embedding\"  # 임베딩이 저장된 속성 이름\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6cabe9",
   "metadata": {},
   "source": [
    "#### 5) **기본 RAG 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b58fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 시스템 구현\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# RAG 프롬프트 템플릿 정의\n",
    "template = \"\"\"\n",
    "당신은 최신 기술 뉴스에 대한 지식을 갖춘 전문가 AI 비서입니다.\n",
    "제공된 뉴스 기사 내용을 바탕으로 질문에 정확하게 답변해 주세요.\n",
    "뉴스 기사에서 찾을 수 없는 정보에 대해서는 솔직하게 모른다고 답변하세요.\n",
    "\n",
    "참고할 뉴스 기사:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG 체인 구성\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "rag_chain = {\n",
    "    \"question\": RunnablePassthrough(), \n",
    "    \"context\": retriever\n",
    "    } | prompt | llm | StrOutputParser()\n",
    "\n",
    "# RAG 실행 \n",
    "answer = rag_chain.invoke(\"엔비디아를 언급한 기사에서는 어떤 기술과 제품이 언급되었나요?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bccae",
   "metadata": {},
   "source": [
    "#### 6) **지식 그래프 강화 RAG 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지식 그래프로 강화된 RAG 시스템 \n",
    "def kg_enhanced_rag(question):\n",
    "    \"\"\"지식 그래프 정보로 강화된 RAG 시스템\"\"\"\n",
    "    try:\n",
    "        # 1. 벡터 검색으로 관련 문서 찾기 \n",
    "        doc_ids = []\n",
    "        try:\n",
    "            docs = vector_store.similarity_search(question, k=2)\n",
    "            \n",
    "            # metadata에 'id' 키가 있는지 확인하고 안전하게 추출\n",
    "            for doc in docs:\n",
    "                if \"id\" in doc.metadata:\n",
    "                    doc_ids.append(doc.metadata[\"id\"])\n",
    "                elif \"title\" in doc.metadata:  # id가 없으면 제목으로 대체\n",
    "                    doc_ids.append(doc.metadata[\"title\"])\n",
    "            \n",
    "            # 원본 문서 내용 가져오기\n",
    "            doc_context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "            \n",
    "        except Exception as vector_error:\n",
    "            print(f\"벡터 검색 오류 발생\")\n",
    "         \n",
    "        # 검색 결과가 없거나 ID를 추출할 수 없는 경우 처리\n",
    "        if not doc_ids:\n",
    "            return {\n",
    "                \"query\": question,\n",
    "                \"result\": \"관련 문서를 찾을 수 없습니다. 다른 질문을 시도해보세요.\",\n",
    "                \"intermediate_steps\": []\n",
    "            }\n",
    "        \n",
    "        # 2. 그래프 검색: 관련 문서에서 언급된 엔티티 및 관계 찾기 \n",
    "        cypher_query = \"\"\"\n",
    "        // 검색 결과와, 일치하는 뉴스 기사 찾기\n",
    "        MATCH (article:NewsArticle)\n",
    "        WHERE article.id IN $doc_ids OR article.title IN $doc_ids\n",
    "        \n",
    "        // 관련 엔티티 찾기 \n",
    "        WITH article\n",
    "        OPTIONAL MATCH (article)-[r1:MENTIONS]->(entity1)\n",
    "        \n",
    "        // 결과 수집 및 가공 (직접 관계 위주)\n",
    "        WITH article, \n",
    "            // 직접 관계 위주로 수집\n",
    "             COLLECT(DISTINCT {\n",
    "                // 엔티티 타입 추출 (기술, 제품, 회사, 인물 등)\n",
    "                 type: CASE WHEN entity1 IS NOT NULL THEN LABELS(entity1)[0] ELSE NULL END, \n",
    "                 // 엔티티 ID 추출 (기술, 제품, 회사, 인물 등의 고유 식별자)\n",
    "                 // COALESCE: NULL이 아닌 첫 번째 값을 반환 -> 엔티티 노드의 id 속성이 NULL인 경우 대신 name 속성을 사용\n",
    "                 id: CASE WHEN entity1 IS NOT NULL THEN COALESCE(entity1.id, entity1.name) ELSE NULL END, \n",
    "                 // 관계 타입 추출 (MENTIONS, 예를 들어, 기술이 제품을 사용한다는 관계)\n",
    "                 rel: TYPE(r1)\n",
    "             }) AS directRelations\n",
    "        \n",
    "        // 최종 결과 반환\n",
    "        RETURN article.id AS article_id, \n",
    "               article.title AS title,\n",
    "               article.text AS text,\n",
    "               directRelations\n",
    "        \"\"\"\n",
    "        \n",
    "        # 그래프 검색 실행 및 결과 처리\n",
    "        graph_results = graph.query(cypher_query, {\"doc_ids\": doc_ids})\n",
    "        print(f\"그래프 검색 결과: {graph_results}\")\n",
    "        print(\"--------------------------------\")\n",
    "        \n",
    "        # 3. 그래프 정보를 텍스트로 변환\n",
    "        kg_context = \"\"\n",
    "        for record in graph_results:\n",
    "            kg_context += f\"기사: {record['title']}\\n\"\n",
    "            \n",
    "            # 관계 정보 추가\n",
    "            kg_context += \"관련 엔티티:\\n\"\n",
    "            for rel in record['directRelations']:\n",
    "                if rel['id'] is not None and rel['type'] is not None:\n",
    "                    kg_context += f\"- {rel['type']}: {rel['id']} (관계: {rel['rel']})\\n\"\n",
    "            \n",
    "            kg_context += \"\\n\"\n",
    "        \n",
    "        # 4. 추가적인 엔티티 관계 탐색 \n",
    "            try:\n",
    "                # 직접 관련된 엔티티 ID 추출\n",
    "                entity_ids = []\n",
    "                for rel in record['directRelations']:\n",
    "                    if rel['id'] is not None:\n",
    "                        entity_ids.append(rel['id'])\n",
    "                \n",
    "                if entity_ids:\n",
    "                    # 엔티티 간 관계 탐색 쿼리\n",
    "                    entity_query = \"\"\"\n",
    "                    MATCH (e1)-[r]->(e2)\n",
    "                    WHERE e1.id IN $entity_ids OR e1.name IN $entity_ids  // 엔티티 ID 또는 이름이 일치하는 경우\n",
    "                    RETURN DISTINCT\n",
    "                           COALESCE(e1.id, e1.name) AS from_entity,  // 엔티티 ID 또는 이름\n",
    "                           LABELS(e1)[0] AS from_type,  // 엔티티 타입\n",
    "                           TYPE(r) AS relation,  // 관계 타입\n",
    "                           COALESCE(e2.id, e2.name) AS to_entity,  // 엔티티 ID 또는 이름\n",
    "                           LABELS(e2)[0] AS to_type  // 엔티티 타입\n",
    "                    LIMIT 10\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    entity_results = graph.query(entity_query, {\"entity_ids\": entity_ids})\n",
    "                    print(f\"엔티티 관계 검색 결과: {entity_results}\")\n",
    "                    print(\"--------------------------------\")\n",
    "                    \n",
    "                    # 엔티티 관계 정보 추가\n",
    "                    if entity_results:\n",
    "                        kg_context += \"엔티티 간 관계:\\n\"\n",
    "                        for relation in entity_results:\n",
    "                            kg_context += f\"- {relation['from_type']} '{relation['from_entity']}' {relation['relation']} {relation['to_type']} '{relation['to_entity']}'\\n\"\n",
    "                        \n",
    "                        kg_context += \"\\n\"\n",
    "            except Exception as entity_error:\n",
    "                print(f\"엔티티 관계 탐색 오류: {str(entity_error)}\")\n",
    "        \n",
    "        # 5. 통합 컨텍스트 생성\n",
    "        combined_context = f\"문서 정보:\\n{doc_context}\\n\\n지식 그래프 정보:\\n{kg_context}\"\n",
    "        \n",
    "        # 6. 프롬프트 템플릿 정의 (간소화된 버전)\n",
    "        kg_template = \"\"\"\n",
    "        당신은 최신 기술 뉴스에 대한 지식을 갖춘 전문가 AI 비서입니다.\n",
    "        제공된 뉴스 기사 내용과 지식 그래프 정보를 바탕으로 질문에 정확하게 답변해 주세요.\n",
    "        \n",
    "        지식 그래프는 뉴스 기사에 언급된 기술, 제품, 회사, 인물 간의 관계를 보여줍니다.\n",
    "        이 관계 정보를 활용하여 더 풍부하고 정확한 답변을 제공하세요.\n",
    "        \n",
    "        뉴스 기사나 지식 그래프에서 찾을 수 없는 정보에 대해서는 솔직하게 모른다고 답변하세요.\n",
    "        답변은 간결하고 명확하게 작성하되, 중요한 세부 정보는 빠짐없이 포함해 주세요.\n",
    "        \n",
    "        참고할 정보:\n",
    "        {context}\n",
    "        \n",
    "        질문: {question}\n",
    "        \n",
    "        답변:\n",
    "        \"\"\"\n",
    "        \n",
    "        kg_prompt = PromptTemplate(\n",
    "            template=kg_template,\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        \n",
    "        # 7. RAG 체인 구성 및 실행\n",
    "        rag_chain = kg_prompt | llm | StrOutputParser()\n",
    "        result = rag_chain.invoke({\n",
    "            \"question\": question, \n",
    "            \"context\": combined_context\n",
    "        })\n",
    "        \n",
    "        # 8. 중간 단계 정보 포함하여 결과 반환\n",
    "        intermediate_steps = [\n",
    "            {\"context\": [dict(record) for record in graph_results]}\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            \"query\": question,\n",
    "            \"result\": result,\n",
    "            \"intermediate_steps\": intermediate_steps\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        # 오류 처리 및 디버깅 정보 반환\n",
    "        return {\n",
    "            \"query\": question,\n",
    "            \"result\": f\"검색 중 오류가 발생했습니다: {str(e)}\",\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# 실행 테스트\n",
    "result = kg_enhanced_rag(\"AI 기술 동향을 분석해주세요.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# 중간 단계 출력\n",
    "for step in result['intermediate_steps']:\n",
    "    pprint(step)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97769015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11826dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
